{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl+dNXa2tIwgZzvZnGBZ3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iremaricii/Cat_or_Dog_Classification/blob/main/ocr_project_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "DRFoxeJ6Wi16",
        "outputId": "acfbb9b0-6fc4-42b2-f168-5d5a7194f211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m608\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m204,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,322\u001b[0m (880.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,322</span> (880.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,322\u001b[0m (880.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,322</span> (880.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2625/2625 - 170s - 65ms/step - accuracy: 0.9521 - loss: 0.1581 - val_accuracy: 0.9607 - val_loss: 0.1646\n",
            "Epoch 2/5\n",
            "2625/2625 - 193s - 74ms/step - accuracy: 0.9828 - loss: 0.0594 - val_accuracy: 0.9906 - val_loss: 0.0355\n",
            "Epoch 3/5\n",
            "2625/2625 - 150s - 57ms/step - accuracy: 0.9880 - loss: 0.0410 - val_accuracy: 0.9919 - val_loss: 0.0323\n",
            "Epoch 4/5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Sabitler ve ayarlar\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "target_size = (28, 28)      # MNIST görüntü boyutu\n",
        "batch_size = 32\n",
        "num_classes = 10            # 0-9 rakamlar\n",
        "\n",
        "##############################################\n",
        "# 1. Veri Setlerinin Oluşturulması\n",
        "##############################################\n",
        "# 1.1 Handwriting (El Yazısı) Verisi: MNIST\n",
        "(x_train_hw, y_train_hw), (x_test_hw, y_test_hw) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 1.2 Typewriter (Daktilo) Verisinin Sentetik Olarak Oluşturulması\n",
        "def generate_typewriter_image(label, target_size=(28,28)):\n",
        "    \"\"\"Belirtilen etiket için beyaz arkaplan üzerine OpenCV ile rakam yazar.\"\"\"\n",
        "    img = np.ones(target_size, dtype=np.uint8) * 255\n",
        "    text = str(label)\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.8\n",
        "    thickness = 2\n",
        "    text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
        "    textX = (target_size[1] - text_size[0]) // 2\n",
        "    textY = (target_size[0] + text_size[1]) // 2\n",
        "    cv2.putText(img, text, (textX, textY), font, font_scale, (0,), thickness, cv2.LINE_AA)\n",
        "    return img\n",
        "\n",
        "x_train_tp = np.array([generate_typewriter_image(label, target_size) for label in y_train_hw])\n",
        "y_train_tp = y_train_hw.copy()\n",
        "x_test_tp = np.array([generate_typewriter_image(label, target_size) for label in y_test_hw])\n",
        "y_test_tp = y_test_hw.copy()\n",
        "\n",
        "##############################################\n",
        "# 2. Eğitim, Doğrulama ve Test Kümelemelerinin Yapılması\n",
        "##############################################\n",
        "# Eğitim/validation bölünmesi (%70/%30) el yazısı ve daktilo için\n",
        "x_train_hw_train, x_train_hw_val, y_train_hw_train, y_train_hw_val = train_test_split(\n",
        "    x_train_hw, y_train_hw, test_size=0.3, random_state=seed)\n",
        "x_train_tp_train, x_train_tp_val, y_train_tp_train, y_train_tp_val = train_test_split(\n",
        "    x_train_tp, y_train_tp, test_size=0.3, random_state=seed)\n",
        "\n",
        "# Test verisi\n",
        "x_test_hw_final, y_test_hw_final = x_test_hw, y_test_hw\n",
        "x_test_tp_final, y_test_tp_final = x_test_tp, y_test_tp\n",
        "\n",
        "# Kanal boyutunu ekleme: (28,28) -> (28,28,1)\n",
        "x_train_hw_train = x_train_hw_train[..., np.newaxis]\n",
        "x_train_tp_train = x_train_tp_train[..., np.newaxis]\n",
        "x_train_hw_val = x_train_hw_val[..., np.newaxis]\n",
        "x_train_tp_val = x_train_tp_val[..., np.newaxis]\n",
        "x_test_hw_final = x_test_hw_final[..., np.newaxis]\n",
        "x_test_tp_final = x_test_tp_final[..., np.newaxis]\n",
        "\n",
        "# Eğitim verilerini birleştirme\n",
        "x_train_combined = np.concatenate([x_train_hw_train, x_train_tp_train], axis=0)\n",
        "y_train_combined = np.concatenate([y_train_hw_train, y_train_tp_train], axis=0)\n",
        "x_val_combined = np.concatenate([x_train_hw_val, x_train_tp_val], axis=0)\n",
        "y_val_combined = np.concatenate([y_train_hw_val, y_train_tp_val], axis=0)\n",
        "x_test_combined = np.concatenate([x_test_hw_final, x_test_tp_final], axis=0)\n",
        "y_test_combined = np.concatenate([y_test_hw_final, y_test_tp_final], axis=0)\n",
        "\n",
        "##############################################\n",
        "# 3. Görüntü Ön İşleme: OpenCV İşlemleri\n",
        "##############################################\n",
        "def cv2_preprocess(image):\n",
        "    \"\"\"\n",
        "    Gelen görüntü için:\n",
        "      - Eğer Tensor ise numpy array'e çevirme,\n",
        "      - Gerekirse kanal boyutunu ayarlama,\n",
        "      - Gaussian blur, Otsu eşikleme ve Canny kenar tespiti uygulama,\n",
        "      - Sonuç olarak 2 kanallı (eşik, kenar) görüntü üretme.\n",
        "    \"\"\"\n",
        "    if isinstance(image, tf.Tensor):\n",
        "        image = image.numpy()\n",
        "    if image.ndim == 3 and image.shape[-1] == 1:\n",
        "        image = np.squeeze(image, axis=-1)\n",
        "    image_uint8 = np.uint8(image)\n",
        "    blurred = cv2.GaussianBlur(image_uint8, (3, 3), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    thresh_norm = thresh.astype('float32') / 255.0\n",
        "    edges = cv2.Canny(blurred, 50, 150)\n",
        "    edges_norm = edges.astype('float32') / 255.0\n",
        "    thresh_norm = np.expand_dims(thresh_norm, axis=-1)\n",
        "    edges_norm = np.expand_dims(edges_norm, axis=-1)\n",
        "    combined = np.concatenate([thresh_norm, edges_norm], axis=-1)\n",
        "    return combined\n",
        "\n",
        "def preprocess_py(image, label):\n",
        "    processed = tf.py_function(func=lambda x: cv2_preprocess(x), inp=[image], Tout=tf.float32)\n",
        "    processed.set_shape((target_size[0], target_size[1], 2))\n",
        "    return processed, label\n",
        "\n",
        "##############################################\n",
        "# 4. tf.data.Dataset Nesnelerinin Oluşturulması\n",
        "##############################################\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train_combined, y_train_combined))\n",
        "train_ds = train_ds.map(preprocess_py, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val_combined, y_val_combined))\n",
        "val_ds = val_ds.map(preprocess_py, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test_combined, y_test_combined))\n",
        "test_ds = test_ds.map(preprocess_py, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "##############################################\n",
        "# 5. Modelin Tanımlanması ve Eğitilmesi\n",
        "##############################################\n",
        "def build_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "input_shape_model = (target_size[0], target_size[1], 2)\n",
        "model = build_model(input_shape_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Eğitim: verbose=2 ile sadece her epoch sonunda özet çıktı alınır.\n",
        "epochs = 5\n",
        "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)\n",
        "\n",
        "##############################################\n",
        "# 6. Eğitim Sonuçlarının Görselleştirilmesi\n",
        "##############################################\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], marker='o', label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], marker='o', label='Val Loss')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], marker='o', label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], marker='o', label='Val Accuracy')\n",
        "plt.title('Accuracy per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "##############################################\n",
        "# 7. Genel Test Sonuçlarının Değerlendirilmesi\n",
        "##############################################\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "print(\"General Test Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[str(i) for i in range(num_classes)],\n",
        "            yticklabels=[str(i) for i in range(num_classes)])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - General Test\")\n",
        "plt.show()\n",
        "\n",
        "##############################################\n",
        "# 8. Ayrı Değerlendirme: Handwriting vs. Typewriter\n",
        "##############################################\n",
        "# Handwriting Test Seti\n",
        "test_ds_hw = tf.data.Dataset.from_tensor_slices((x_test_hw_final, y_test_hw_final))\n",
        "test_ds_hw = test_ds_hw.map(preprocess_py, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds_hw = test_ds_hw.batch(batch_size)\n",
        "y_true_hw = []\n",
        "y_pred_hw = []\n",
        "for images, labels in test_ds_hw:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true_hw.extend(labels.numpy())\n",
        "    y_pred_hw.extend(np.argmax(preds, axis=1))\n",
        "print(\"Handwriting Test Classification Report:\")\n",
        "print(classification_report(y_true_hw, y_pred_hw, digits=4))\n",
        "cm_hw = confusion_matrix(y_true_hw, y_pred_hw)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_hw, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=[str(i) for i in range(num_classes)],\n",
        "            yticklabels=[str(i) for i in range(num_classes)])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - Handwriting Test\")\n",
        "plt.show()\n",
        "\n",
        "# Typewriter Test Seti\n",
        "test_ds_tp = tf.data.Dataset.from_tensor_slices((x_test_tp_final, y_test_tp_final))\n",
        "test_ds_tp = test_ds_tp.map(preprocess_py, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds_tp = test_ds_tp.batch(batch_size)\n",
        "y_true_tp = []\n",
        "y_pred_tp = []\n",
        "for images, labels in test_ds_tp:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true_tp.extend(labels.numpy())\n",
        "    y_pred_tp.extend(np.argmax(preds, axis=1))\n",
        "print(\"Typewriter Test Classification Report:\")\n",
        "print(classification_report(y_true_tp, y_pred_tp, digits=4))\n",
        "cm_tp = confusion_matrix(y_true_tp, y_pred_tp)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_tp, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=[str(i) for i in range(num_classes)],\n",
        "            yticklabels=[str(i) for i in range(num_classes)])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - Typewriter Test\")\n",
        "plt.show()\n",
        "\n",
        "##############################################\n",
        "# 9. Ek Profesyonel Görselleştirmeler\n",
        "##############################################\n",
        "# 9.1 t-SNE Görselleştirmesi (Özellik Uzayı)\n",
        "# Modelin ilk katmanının girişini kullanarak feature_model oluşturuyoruz.\n",
        "feature_model = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[5].output)\n",
        "features = feature_model.predict(test_ds, verbose=0)\n",
        "tsne = TSNE(n_components=2, random_state=seed, perplexity=30)\n",
        "tsne_results = tsne.fit_transform(features)\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=y_true, cmap='tab10', s=10)\n",
        "plt.colorbar(scatter, ticks=range(num_classes))\n",
        "plt.title(\"t-SNE Visualization - General Test Features\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "features_hw = feature_model.predict(test_ds_hw, verbose=0)\n",
        "tsne_hw = TSNE(n_components=2, random_state=seed, perplexity=30)\n",
        "tsne_results_hw = tsne_hw.fit_transform(features_hw)\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(tsne_results_hw[:, 0], tsne_results_hw[:, 1], c=y_true_hw, cmap='tab10', s=10)\n",
        "plt.colorbar(scatter, ticks=range(num_classes))\n",
        "plt.title(\"t-SNE Visualization - Handwriting Test Features\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "features_tp = feature_model.predict(test_ds_tp, verbose=0)\n",
        "tsne_tp = TSNE(n_components=2, random_state=seed, perplexity=30)\n",
        "tsne_results_tp = tsne_tp.fit_transform(features_tp)\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(tsne_results_tp[:, 0], tsne_results_tp[:, 1], c=y_true_tp, cmap='tab10', s=10)\n",
        "plt.colorbar(scatter, ticks=range(num_classes))\n",
        "plt.title(\"t-SNE Visualization - Typewriter Test Features\")\n",
        "plt.xlabel(\"t-SNE Component 1\")\n",
        "plt.ylabel(\"t-SNE Component 2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 9.2 Sınıf Bazlı Metrik Bar Grafiği (Precision, Recall, F1)\n",
        "report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
        "classes = [str(i) for i in range(num_classes)]\n",
        "precision_vals = [report_dict[str(i)]['precision'] for i in range(num_classes)]\n",
        "recall_vals = [report_dict[str(i)]['recall'] for i in range(num_classes)]\n",
        "f1_vals = [report_dict[str(i)]['f1-score'] for i in range(num_classes)]\n",
        "plt.figure(figsize=(10,6))\n",
        "x_axis = np.arange(num_classes)\n",
        "width = 0.25\n",
        "plt.bar(x_axis - width, precision_vals, width, label='Precision')\n",
        "plt.bar(x_axis, recall_vals, width, label='Recall')\n",
        "plt.bar(x_axis + width, f1_vals, width, label='F1-score')\n",
        "plt.xticks(x_axis, classes)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Classification Metrics per Class')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 9.3 Rastgele Test Örneklerinin Görselleştirilmesi\n",
        "all_images = []\n",
        "all_labels = []\n",
        "for images, labels in test_ds:\n",
        "    for i in range(images.shape[0]):\n",
        "        all_images.append(images[i])\n",
        "        all_labels.append(labels.numpy()[i])\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "preds = model.predict(test_ds, verbose=0)\n",
        "all_preds = np.argmax(preds, axis=1)\n",
        "n_display = 12\n",
        "indices = np.random.choice(len(all_images), n_display, replace=False)\n",
        "plt.figure(figsize=(12, 8))\n",
        "for j, idx in enumerate(indices):\n",
        "    img = all_images[idx].numpy() if isinstance(all_images[idx], tf.Tensor) else all_images[idx]\n",
        "    img_disp = img[:, :, 0]\n",
        "    true_label = all_labels[idx]\n",
        "    pred_label = all_preds[idx]\n",
        "    plt.subplot(3, 4, j+1)\n",
        "    plt.imshow(img_disp, cmap='gray')\n",
        "    plt.title(f\"True: {true_label}, Pred: {pred_label}\")\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Random Test Examples\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ]
}